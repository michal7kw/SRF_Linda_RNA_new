{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8640f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "import gseapy as gp\n",
    "\n",
    "# --- Configuration ---\n",
    "PROJECT_DIR = \"D:/Github/SRF_Linda_RNA\"\n",
    "WORKING_DIR = f\"{PROJECT_DIR}/combine_data\"\n",
    "os.chdir(WORKING_DIR)\n",
    "sys.path.insert(0, WORKING_DIR)\n",
    "\n",
    "ORGANISM = 'Mouse'\n",
    "\n",
    "# Set up directories\n",
    "REMOVE_DOUBLETS = False\n",
    "FIX_TRESHOLD = True\n",
    "\n",
    "if FIX_TRESHOLD:\n",
    "    BASE_RESULTS_DIR = os.path.join(WORKING_DIR, \"results_from_raw\")\n",
    "else:\n",
    "    if REMOVE_DOUBLETS:\n",
    "        BASE_RESULTS_DIR = os.path.join(WORKING_DIR, \"results_from_raw_percentile_threshold\", \"doublets_removed\")\n",
    "    else:\n",
    "        BASE_RESULTS_DIR = os.path.join(WORKING_DIR, \"results_from_raw_percentile_threshold\")\n",
    "\n",
    "INPUT_DIR = BASE_RESULTS_DIR\n",
    "ADATA_PATH = os.path.join(INPUT_DIR, \"annotation_final.h5ad\")\n",
    "\n",
    "DGE_RESULTS_DIR_BASE = os.path.join(INPUT_DIR,\"DEGs_cell_type_L2\")\n",
    "\n",
    "CUSTOM_ANALYSIS =  \"FC_0_25\"\n",
    "\n",
    "DEG_BY = \"cell_type_L2\"\n",
    "DEGs_folder = \"DEGs_cell_type_L2FC_0_25\"\n",
    "\n",
    "if CUSTOM_ANALYSIS is not None:\n",
    "    DGE_RESULTS_DIR = DGE_RESULTS_DIR_BASE + CUSTOM_ANALYSIS\n",
    "else:\n",
    "    DGE_RESULTS_DIR = DGE_RESULTS_DIR_BASE\n",
    "\n",
    "DGE_RESULTS_DIR = os.path.join(DGE_RESULTS_DIR,\"biomarkers\")\n",
    "GO_OUTPUT_DIR = os.path.join(DGE_RESULTS_DIR, 'go_enrichment_combined') # New output directory\n",
    "GENE_SETS = ['GO_Biological_Process_2023', 'GO_Cellular_Component_2023', 'GO_Molecular_Function_2023']\n",
    "\n",
    "N_TOP_TERMS_PLOT = 10\n",
    "GO_PADJ_THRESHOLD = 0.05\n",
    "\n",
    "# --- End Configuration ---\n",
    "\n",
    "# Create base output directory if it doesn't exist\n",
    "GO_OUTPUT_DIR = pathlib.Path(GO_OUTPUT_DIR)\n",
    "GO_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"DGE results input directory: {DGE_RESULTS_DIR}\")\n",
    "print(f\"GO results output directory: {GO_OUTPUT_DIR}\")\n",
    "print(f\"Organism: {ORGANISM}\")\n",
    "print(f\"Gene sets: {GENE_SETS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f5100d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available gene sets for the organism\n",
    "try:\n",
    "    print(f\"Checking available Enrichr libraries for organism: {ORGANISM}...\")\n",
    "    available_sets = gp.get_library_name(organism=ORGANISM)\n",
    "    print(f\"Found {len(available_sets)} libraries.\")\n",
    "    for gs in GENE_SETS:\n",
    "        if gs not in available_sets:\n",
    "            print(f\"WARNING: Specified gene set '{gs}' not found in available Enrichr libraries for {ORGANISM}!\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not retrieve available gene sets from Enrichr: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f565ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the AnnData object to get the full list of genes (gene universe)\n",
    "print(f\"Loading AnnData from {ADATA_PATH} to get gene universe...\")\n",
    "try:\n",
    "    adata = sc.read_h5ad(ADATA_PATH)\n",
    "    print(adata)\n",
    "    gene_universe = adata.var_names.tolist()\n",
    "    print(f\"Using {len(gene_universe)} genes as the background universe.\")\n",
    "    del adata\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: AnnData file not found at {ADATA_PATH}. Cannot determine gene universe.\")\n",
    "    sys.exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading AnnData file: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc49d07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all significant DEG list files recursively\n",
    "deg_list_files = list(pathlib.Path(DGE_RESULTS_DIR).rglob('*_significant.csv'))\n",
    "print(f\"Found {len(deg_list_files)} significant DEG list files to process.\")\n",
    "\n",
    "if not deg_list_files:\n",
    "    print(f\"Error: No significant DEG list files found matching '*_significant.csv' within {DGE_RESULTS_DIR}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Group DEG files by cell type and comparison name\n",
    "grouped_deg_files = {}\n",
    "for deg_file_path in deg_list_files:\n",
    "    parts = deg_file_path.parts\n",
    "    try:\n",
    "        base_index = parts.index(DEGs_folder)\n",
    "        if base_index + 1 < len(parts) and parts[base_index + 1] == 'biomarkers':\n",
    "            biomarkers_index = base_index + 1\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        if biomarkers_index + 1 >= len(parts) or parts[biomarkers_index + 1] != 'sig_deg_lists':\n",
    "            continue\n",
    "\n",
    "        context_start_index = biomarkers_index + 2\n",
    "        sub_path_parts = parts[context_start_index:]\n",
    "\n",
    "        if len(sub_path_parts) < 2:\n",
    "            continue\n",
    "\n",
    "        cell_type_name = sub_path_parts[0]\n",
    "        filename = deg_file_path.name\n",
    "        \n",
    "        # Determine comparison_name and direction based on filename\n",
    "        if '_up_significant.csv' in filename:\n",
    "            direction = 'up'\n",
    "            comparison_name = filename.replace('_up_significant.csv', '')\n",
    "        elif '_down_significant.csv' in filename:\n",
    "            direction = 'down'\n",
    "            comparison_name = filename.replace('_down_significant.csv', '')\n",
    "        else:\n",
    "            direction = 'unknown'\n",
    "            comparison_name = filename.replace('_significant.csv', '')\n",
    "\n",
    "        key = (cell_type_name, comparison_name)\n",
    "        if key not in grouped_deg_files:\n",
    "            grouped_deg_files[key] = {}\n",
    "        grouped_deg_files[key][direction] = deg_file_path\n",
    "    except ValueError:\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"Error grouping file {deg_file_path}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"Found {len(grouped_deg_files)} unique comparisons to process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b988efc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grouped_deg_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf94cfc6",
   "metadata": {
    "lines_to_next_cell": 3
   },
   "outputs": [],
   "source": [
    "# Process each grouped DEG list - iterate through all cell type and comparison combinations\n",
    "for (cell_type_name, comparison_name), files in grouped_deg_files.items():\n",
    "    print(f\"\\n--- Processing comparison: {comparison_name} for cell type: {cell_type_name} ---\")\n",
    "\n",
    "    # Initialize variables to store gene lists and processing metadata\n",
    "    gene_list_combined = []\n",
    "    processing_type = \"\"\n",
    "    output_file_suffix = \"\"\n",
    "    \n",
    "    # Extract UP and DOWN regulated gene files for this comparison\n",
    "    up_file = files.get('up')\n",
    "    down_file = files.get('down')\n",
    "\n",
    "    # Initialize empty DataFrames for UP and DOWN gene data\n",
    "    df_up = pd.DataFrame()\n",
    "    df_down = pd.DataFrame()\n",
    "\n",
    "    # Read and process UP-regulated genes if file exists\n",
    "    if up_file:\n",
    "        try:\n",
    "            df_up = pd.read_csv(up_file)\n",
    "            # Extract gene names from 'names' column and add to combined list\n",
    "            if 'names' in df_up.columns:\n",
    "                gene_list_combined.extend(df_up['names'].dropna().astype(str).tolist())\n",
    "            print(f\"  Read {len(df_up)} genes from {up_file.name} (UP)\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error reading UP file {up_file.name}: {e}\")\n",
    "\n",
    "    # Read and process DOWN-regulated genes if file exists\n",
    "    if down_file:\n",
    "        try:\n",
    "            df_down = pd.read_csv(down_file)\n",
    "            # Extract gene names from 'names' column and add to combined list\n",
    "            if 'names' in df_down.columns:\n",
    "                gene_list_combined.extend(df_down['names'].dropna().astype(str).tolist())\n",
    "            print(f\"  Read {len(df_down)} genes from {down_file.name} (DOWN)\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error reading DOWN file {down_file.name}: {e}\")\n",
    "\n",
    "    # Determine the type of analysis based on available files and set appropriate output suffix\n",
    "    if up_file and down_file:\n",
    "        processing_type = \"Combined UP & DOWN\"\n",
    "        output_file_suffix = \"_combined\"\n",
    "    elif up_file:\n",
    "        processing_type = \"UP only\"\n",
    "        output_file_suffix = \"_up\"\n",
    "    elif down_file:\n",
    "        processing_type = \"DOWN only\"\n",
    "        output_file_suffix = \"_down\"\n",
    "    else:\n",
    "        print(\"  No UP or DOWN files found for this comparison. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Skip processing if no genes were found in the files\n",
    "    if not gene_list_combined:\n",
    "        print(f\"  Combined gene list for {comparison_name} is empty. Skipping enrichment analysis.\")\n",
    "        continue\n",
    "\n",
    "    # Remove duplicate genes and report final count\n",
    "    gene_list_combined = list(set(gene_list_combined)) # Remove duplicates\n",
    "    print(f\"  Total {len(gene_list_combined)} unique genes for {processing_type} analysis.\")\n",
    "\n",
    "    # --- Prepare Output Directory and File Paths ---\n",
    "    # Sanitize cell type name for file system compatibility (replace '/' with '_')\n",
    "    sanitized_cell_type = cell_type_name.replace('/', '_')\n",
    "    # Create output directory specific to this cell type\n",
    "    specific_go_output_dir = pathlib.Path(os.path.join(GO_OUTPUT_DIR, sanitized_cell_type))\n",
    "    specific_go_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Define output file names for Excel results and dotplot visualization\n",
    "    output_file_base = f\"{comparison_name}{output_file_suffix}\"\n",
    "    excel_output = os.path.join(specific_go_output_dir, f\"{output_file_base}_go_enrichment.xlsx\")\n",
    "    dotplot_output_file = os.path.join(specific_go_output_dir, f\"{output_file_base}_go_enrichment_dotplot.png\")\n",
    "\n",
    "    # Create descriptive title for plots\n",
    "    plot_title = f\"GO Enrichment: {sanitized_cell_type} Biomarkers\\n{comparison_name} ({processing_type})\"\n",
    "\n",
    "    # --- Run GO Enrichment Analysis ---\n",
    "    print(f\"  Running GO enrichment for {len(gene_list_combined)} genes ({processing_type})...\")\n",
    "    try:\n",
    "        # Perform enrichment analysis using gseapy.enrichr\n",
    "        enr = gp.enrichr(gene_list=gene_list_combined,\n",
    "                         gene_sets=GENE_SETS,\n",
    "                         organism=ORGANISM,\n",
    "                         background=gene_universe,\n",
    "                         outdir=None,\n",
    "                         cutoff=0.1,\n",
    "                         verbose=False)\n",
    "    except Exception as enrich_err:\n",
    "         print(f\"  Error during gseapy.enrichr execution for {comparison_name} ({processing_type}): {enrich_err}\")\n",
    "         continue\n",
    "\n",
    "    # --- Process and Save Enrichment Results ---\n",
    "    # Check if enrichment analysis returned valid results\n",
    "    if enr and hasattr(enr, 'results') and isinstance(enr.results, pd.DataFrame) and not enr.results.empty:\n",
    "        print(\"  Filtering and saving enrichment results...\")\n",
    "        # Filter results to only include significantly enriched terms (adjusted p-value < threshold)\n",
    "        filtered_results = enr.results[enr.results['Adjusted P-value'] < GO_PADJ_THRESHOLD].copy()\n",
    "\n",
    "        if not filtered_results.empty:\n",
    "             print(f\"  Found {len(filtered_results)} significant terms (Adj P < {GO_PADJ_THRESHOLD}).\")\n",
    "             \n",
    "             # Calculate gene count for each enriched term if 'Genes' column exists\n",
    "             if 'Genes' in filtered_results.columns:\n",
    "                 # Count number of genes in each term by splitting the semicolon-separated gene list\n",
    "                 filtered_results['Gene_Count'] = filtered_results['Genes'].apply(\n",
    "                     lambda x: len(str(x).split(';')) if pd.notna(x) and str(x) else 0\n",
    "                 )\n",
    "                 filtered_results['Gene_Count'] = pd.to_numeric(filtered_results['Gene_Count'], errors='coerce').fillna(1.0)\n",
    "             else:\n",
    "                 print(\"  Warning: 'Genes' column not found. Using default size.\")\n",
    "                 filtered_results['Gene_Count'] = 1.0\n",
    "\n",
    "             # Save filtered results to Excel file\n",
    "             try:\n",
    "                 filtered_results.to_excel(excel_output, index=False)\n",
    "                 print(f\"  Saved significant results to {excel_output}\")\n",
    "             except Exception as excel_err:\n",
    "                 print(f\"  Error saving Excel file: {excel_err}\")\n",
    "\n",
    "             # --- Generate Visualization ---\n",
    "             try:\n",
    "                 # Select top terms for visualization (limited by N_TOP_TERMS_PLOT * number of gene sets)\n",
    "                 plot_data = filtered_results.sort_values(\"Adjusted P-value\").head(N_TOP_TERMS_PLOT * len(GENE_SETS)).copy()\n",
    "\n",
    "                 if not plot_data.empty:\n",
    "                     # Convert numeric columns to proper data types for plotting\n",
    "                     for col in ['P-value', 'Adjusted P-value', 'Odds Ratio', 'Combined Score', 'Gene_Count']:\n",
    "                         if col in plot_data.columns:\n",
    "                             plot_data[col] = pd.to_numeric(plot_data[col], errors='coerce')\n",
    "                     \n",
    "                     # Remove rows with missing adjusted p-values\n",
    "                     plot_data.dropna(subset=['Adjusted P-value'], inplace=True)\n",
    "\n",
    "                     if not plot_data.empty:\n",
    "                         print(\"  Data types before plotting:\")\n",
    "                         print(plot_data.dtypes)\n",
    "                         print(f\"  Generating visualizations for {len(plot_data)} enriched terms...\")\n",
    "                         \n",
    "                         try:\n",
    "                             print(f\"  Creating dotplot visualization: {dotplot_output_file}\")\n",
    "                             \n",
    "                             # Select top 15 most significant terms for the plot\n",
    "                             top_overall = plot_data.sort_values('Adjusted P-value').head(15)\n",
    "                             \n",
    "                             if not top_overall.empty:\n",
    "                                 # Clean up term names by removing GO IDs and replacing underscores\n",
    "                                 top_overall['Clean_Term'] = top_overall['Term'].str.replace(r' \\(GO:[0-9]+\\)', '', regex=True)\n",
    "                                 top_overall['Clean_Term'] = top_overall['Clean_Term'].str.replace('_', ' ')\n",
    "                                 \n",
    "                                 # Calculate gene ratio (normalized by maximum gene count)\n",
    "                                 top_overall['GeneRatio'] = top_overall['Gene_Count'] / top_overall['Gene_Count'].max()\n",
    "                                 \n",
    "                                 # Sort by adjusted p-value for better visualization\n",
    "                                 top_overall = top_overall.sort_values('Adjusted P-value', ascending=False)\n",
    "                                 \n",
    "                                 # Create figure with dynamic height based on number of terms\n",
    "                                 plt.figure(figsize=(10, max(6, len(top_overall) * 0.4)))\n",
    "                                 \n",
    "                                 # Create scatter plot with constant dot size\n",
    "                                 scatter = plt.scatter(\n",
    "                                     top_overall['GeneRatio'],\n",
    "                                     top_overall['Clean_Term'],\n",
    "                                     s=100,  # Constant dot size\n",
    "                                     c=-np.log10(top_overall['Adjusted P-value']),  # Color by significance\n",
    "                                     cmap='Reds',\n",
    "                                     alpha=0.8\n",
    "                                 )\n",
    "                                 \n",
    "                                 # Add gene count text next to each dot\n",
    "                                 for idx, row in top_overall.iterrows():\n",
    "                                     plt.text(row['GeneRatio'] + 0.02, row['Clean_Term'], \n",
    "                                             f\"({int(row['Gene_Count'])})\", \n",
    "                                             va='center', ha='left', fontsize=9)\n",
    "                                 \n",
    "                                 # Set plot labels and title\n",
    "                                 plt.xlabel('GeneRatio')\n",
    "                                 plt.ylabel('')\n",
    "                                 plt.title(f\"{plot_title}\\nTop GO Terms\")\n",
    "                                 plt.grid(True, alpha=0.3, axis='x')\n",
    "                                 \n",
    "                                 cbar = plt.colorbar(scatter)\n",
    "                                 cbar.set_label('-log10(Adj. P-value)')\n",
    "                                 \n",
    "                                 valid_counts = top_overall['Gene_Count'].dropna().unique()\n",
    "                                 if len(valid_counts) > 0:\n",
    "                                     size_steps = sorted(list(valid_counts))\n",
    "                                     if len(size_steps) > 3:\n",
    "                                         size_steps = [min(size_steps),\n",
    "                                                       np.percentile(size_steps, 50),\n",
    "                                                       max(size_steps)]\n",
    "                                 else:\n",
    "                                     size_steps = []\n",
    "                                 # Remove the legend for gene count (no plt.scatter for legend, no plt.legend)\n",
    "                                 # for count in size_steps:\n",
    "                                 #     plt.scatter([], [], s=np.minimum(count * 5, 400), c='black',\n",
    "                                 #               label=f'{int(count)}')\n",
    "                                 # plt.legend(title=\"Gene Count\", loc='lower right', frameon=True)\n",
    "                                 \n",
    "                                 plt.tight_layout()\n",
    "                                 plt.savefig(dotplot_output_file, dpi=150, bbox_inches='tight')\n",
    "                                 plt.close()\n",
    "                                 \n",
    "                                 print(f\"  Dotplot saved to {dotplot_output_file}\")\n",
    "                         except Exception as dotplot_err:\n",
    "                             print(f\"  Error generating dotplot: {dotplot_err}\")\n",
    "                     else:\n",
    "                         print(\"  No significant terms left after filtering for visualization.\")\n",
    "                 else:\n",
    "                     print(\"  No significant terms left after filtering for visualization.\")\n",
    "             except Exception as viz_err:\n",
    "                 print(f\"  Warning: Could not generate visualizations. Error: {viz_err}\")\n",
    "        else:\n",
    "            print(f\"  No significantly enriched terms found after filtering (Adj P < {GO_PADJ_THRESHOLD}). No Excel file or visualizations saved.\")\n",
    "    else:\n",
    "         print(\"  Enrichment analysis did not return results or results table was empty.\")\n",
    "\n",
    "print(\"\\nGO enrichment analysis for DEG lists complete.\")\n",
    "print(f\"Results saved in subdirectories under: {GO_OUTPUT_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
